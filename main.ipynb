{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from personalized_popularity_based_method import personalized_popularity_based_method\n",
    "from global_popularity_based_method import global_popularity_based_method\n",
    "from chatgpt import LLM_chatpgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data.json', 'r') as f:\n",
    "    # Load the file contents into a dictionary using json.load()\n",
    "    training_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_user_items.csv')\n",
    "df_labels = pd.read_csv('data_last_item_user_bought.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels = df_labels.sample(n=150, random_state=42)\n",
    "users_list = list(sample_labels['reviewerID'])\n",
    "training_data_sampled = {key: training_data[key] for key in users_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 items for users predicted\n",
      "1 items for users predicted\n",
      "2 items for users predicted\n",
      "3 items for users predicted\n",
      "4 items for users predicted\n",
      "5 items for users predicted\n",
      "6 items for users predicted\n",
      "7 items for users predicted\n",
      "8 items for users predicted\n",
      "9 items for users predicted\n",
      "10 items for users predicted\n",
      "11 items for users predicted\n",
      "12 items for users predicted\n",
      "13 items for users predicted\n",
      "14 items for users predicted\n",
      "15 items for users predicted\n",
      "16 items for users predicted\n",
      "17 items for users predicted\n",
      "18 items for users predicted\n",
      "19 items for users predicted\n",
      "20 items for users predicted\n",
      "21 items for users predicted\n",
      "22 items for users predicted\n",
      "23 items for users predicted\n",
      "24 items for users predicted\n",
      "25 items for users predicted\n",
      "26 items for users predicted\n",
      "27 items for users predicted\n",
      "28 items for users predicted\n",
      "29 items for users predicted\n",
      "30 items for users predicted\n",
      "31 items for users predicted\n",
      "32 items for users predicted\n",
      "33 items for users predicted\n",
      "34 items for users predicted\n",
      "35 items for users predicted\n",
      "36 items for users predicted\n",
      "37 items for users predicted\n",
      "38 items for users predicted\n",
      "39 items for users predicted\n",
      "40 items for users predicted\n",
      "41 items for users predicted\n",
      "42 items for users predicted\n",
      "43 items for users predicted\n",
      "44 items for users predicted\n",
      "45 items for users predicted\n",
      "46 items for users predicted\n",
      "47 items for users predicted\n",
      "48 items for users predicted\n",
      "49 items for users predicted\n",
      "50 items for users predicted\n",
      "51 items for users predicted\n",
      "52 items for users predicted\n",
      "53 items for users predicted\n",
      "54 items for users predicted\n",
      "55 items for users predicted\n",
      "56 items for users predicted\n",
      "57 items for users predicted\n",
      "58 items for users predicted\n",
      "59 items for users predicted\n",
      "60 items for users predicted\n",
      "61 items for users predicted\n",
      "62 items for users predicted\n",
      "63 items for users predicted\n",
      "64 items for users predicted\n",
      "65 items for users predicted\n",
      "66 items for users predicted\n",
      "67 items for users predicted\n",
      "68 items for users predicted\n",
      "69 items for users predicted\n",
      "70 items for users predicted\n",
      "71 items for users predicted\n",
      "72 items for users predicted\n",
      "73 items for users predicted\n",
      "74 items for users predicted\n",
      "75 items for users predicted\n",
      "76 items for users predicted\n",
      "77 items for users predicted\n",
      "78 items for users predicted\n",
      "79 items for users predicted\n",
      "80 items for users predicted\n",
      "81 items for users predicted\n",
      "82 items for users predicted\n",
      "83 items for users predicted\n",
      "84 items for users predicted\n",
      "85 items for users predicted\n",
      "86 items for users predicted\n",
      "87 items for users predicted\n",
      "88 items for users predicted\n",
      "89 items for users predicted\n",
      "90 items for users predicted\n",
      "91 items for users predicted\n",
      "92 items for users predicted\n",
      "93 items for users predicted\n",
      "94 items for users predicted\n",
      "95 items for users predicted\n",
      "96 items for users predicted\n",
      "97 items for users predicted\n",
      "98 items for users predicted\n",
      "99 items for users predicted\n",
      "100 items for users predicted\n",
      "101 items for users predicted\n",
      "102 items for users predicted\n",
      "103 items for users predicted\n",
      "104 items for users predicted\n",
      "105 items for users predicted\n",
      "106 items for users predicted\n",
      "107 items for users predicted\n",
      "108 items for users predicted\n",
      "109 items for users predicted\n",
      "110 items for users predicted\n",
      "111 items for users predicted\n",
      "112 items for users predicted\n",
      "113 items for users predicted\n",
      "114 items for users predicted\n",
      "115 items for users predicted\n",
      "116 items for users predicted\n",
      "117 items for users predicted\n",
      "118 items for users predicted\n",
      "119 items for users predicted\n",
      "120 items for users predicted\n",
      "121 items for users predicted\n",
      "122 items for users predicted\n",
      "123 items for users predicted\n",
      "124 items for users predicted\n",
      "125 items for users predicted\n",
      "126 items for users predicted\n",
      "127 items for users predicted\n",
      "128 items for users predicted\n",
      "129 items for users predicted\n",
      "130 items for users predicted\n",
      "131 items for users predicted\n",
      "132 items for users predicted\n",
      "133 items for users predicted\n",
      "134 items for users predicted\n",
      "135 items for users predicted\n",
      "136 items for users predicted\n",
      "137 items for users predicted\n",
      "138 items for users predicted\n",
      "139 items for users predicted\n",
      "140 items for users predicted\n",
      "141 items for users predicted\n",
      "142 items for users predicted\n",
      "143 items for users predicted\n",
      "144 items for users predicted\n",
      "145 items for users predicted\n",
      "146 items for users predicted\n",
      "147 items for users predicted\n",
      "148 items for users predicted\n",
      "149 items for users predicted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amount correct: 18 and the HR@10: 0.12'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_chatpgt(training_data_sampled, sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount correct: 1 and the HR@10: 0.006666666666666667'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_popularity_based_method(data, sample_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 items for users predicited\n",
      "10 items for users predicited\n",
      "20 items for users predicited\n",
      "30 items for users predicited\n",
      "40 items for users predicited\n",
      "50 items for users predicited\n",
      "60 items for users predicited\n",
      "70 items for users predicited\n",
      "80 items for users predicited\n",
      "90 items for users predicited\n",
      "100 items for users predicited\n",
      "110 items for users predicited\n",
      "120 items for users predicited\n",
      "130 items for users predicited\n",
      "140 items for users predicited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amount correct: 0 and the HR@10: 0.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalized_popularity_based_method(data, sample_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
